{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "twelve-reporter",
   "metadata": {},
   "source": [
    "Adding all datasets together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "secondary-retirement",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from pathlib import Path\n",
    "\n",
    "import pandas as pd\n",
    "import json\n",
    "import csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "collaborative-circus",
   "metadata": {},
   "source": [
    "### Conan dataset:\n",
    "\n",
    "Hate  speech  collection: For  each  language we asked two native speaker experts (NGO train-ers) to write around 50 prototypical islamophobic short hate texts. This step was used to ensure that:(i) the sample uniformly covers the typical ‘arguments’ against Islam as much as possible, (ii) wecan distribute to the NLP community the originalhate speech as well as its counter-narrative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "empty-leonard",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(r'../data/conan/CONAN.json') as json_file:\n",
    "    data = json.load(json_file)\n",
    "conan = (pd.DataFrame.from_dict(data=data['conan'][0], orient='index')).T\n",
    "for i in range(len(data['conan'])):\n",
    "    sett = (pd.DataFrame.from_dict(data=data['conan'][i], orient='index')).T\n",
    "    if sett['cn_id'][0][0:2] == 'EN':\n",
    "        conan = conan.append(sett, ignore_index=True)\n",
    "conan_dt = pd.DataFrame(conan.hateSpeech.unique())\n",
    "conan_dt['classification'] = 'islamophobic'\n",
    "conan_dt.columns = ['text', 'classification']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "promising-message",
   "metadata": {},
   "source": [
    "### LoL dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "lonely-vacuum",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\envs\\nlp-course-fri\\lib\\site-packages\\pandas\\core\\generic.py:5170: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self[name] = value\n"
     ]
    }
   ],
   "source": [
    "lol = pd.read_csv (r'../data/lol/lol_data_ok.csv')\n",
    "lol_data = lol[lol['classification'] != 'neutral']\n",
    "lol_data.classification = lol_data.classification.replace('harrasment', 'cyberbullying')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "unknown-neighbor",
   "metadata": {},
   "source": [
    "### Reddit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fiscal-ordering",
   "metadata": {},
   "outputs": [],
   "source": [
    "reddit = pd.read_csv (r'../data/reddit_binary-jing-qian/reddit.csv')\n",
    "red_data = reddit[reddit['hate_speech_idx'].isnull() == False][['text']]\n",
    "red_data['classification'] = 'hateful'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "removable-spending",
   "metadata": {},
   "source": [
    "### Gab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "civilian-tablet",
   "metadata": {},
   "outputs": [],
   "source": [
    "gab = pd.read_csv(r'../data/gab_binary-jing-qian/gab.csv')\n",
    "gab_data = gab[~gab['hate_speech_idx'].isnull()][['text']]\n",
    "gab_data['classification'] = 'hateful'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "czech-advertising",
   "metadata": {},
   "source": [
    "### Twitter hierarchy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "governmental-theme",
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter_hierarchy = pd.read_csv (r'../data/twitter_hierarchy_t-davidson/labeled_data.csv')\n",
    "twitter_h = twitter_hierarchy[twitter_hierarchy['offensive_language'] > 0][['tweet']]\n",
    "twitter_h['classification'] = 'offensive' \n",
    "twitter_h.columns = ['text', 'classification']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "thrown-compound",
   "metadata": {},
   "source": [
    "### Abusive speech"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "unsigned-sudan",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "hate_speech = pd.read_csv (r'../data/multilingual_and_multi-aspect_hate_speech_analysis/hate_speech_mlma/en_dataset.csv')\n",
    "abusive = hate_speech[hate_speech['sentiment'].str.contains(\"abusive\")][['tweet']]\n",
    "abusive['classification'] = 'abusive' \n",
    "abusive.columns = ['text', 'classification']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abroad-globe",
   "metadata": {},
   "source": [
    "### Online hate speech"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "declared-express",
   "metadata": {},
   "outputs": [],
   "source": [
    "personal_attack = pd.read_csv(r'../data/personal_attacks_seen_at_scale_wulczyn/train.csv')\n",
    "insults = personal_attack[personal_attack.Insult == 1][['Comment']]\n",
    "insults['classification'] = 'insult' \n",
    "insults.columns = ['text', 'classification']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "desperate-differential",
   "metadata": {},
   "source": [
    "### White suppremacy forum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "economic-french",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "annotations = pd.read_csv(r'../data/stormfront_ternary_vicomtech/annotations_metadata.csv')\n",
    "hates = list()\n",
    "for file in annotations[annotations['label'] == 'hate'].file_id.unique():\n",
    "    hates_dt = pd.read_csv('../data/stormfront_ternary_vicomtech/all_files/' + str(file) + '.txt', header = None)\n",
    "    hates.append(hates_dt[0][0])\n",
    "hates = pd.DataFrame(hates)\n",
    "hates['classification'] = 'hateful' \n",
    "hates.columns = ['text', 'classification']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "still-softball",
   "metadata": {},
   "source": [
    "### Multimodal twitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fancy-break",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = Path(\"../data/twitter_mutlimodal_hate_speech\")\n",
    "\n",
    "with open(data_dir / \"MMHS150K_GT.json\", \"r\") as json_file:\n",
    "    data = json.load(json_file)\n",
    "\n",
    "twits = []\n",
    "for key, value in data.items():\n",
    "    value[\"tweet_id\"] = key\n",
    "    try:\n",
    "        with open(data_dir / \"img_txt\" / f\"{key}.json\") as img_txt:\n",
    "            img_txt = json.load(img_txt)\n",
    "        value[\"img_text\"] = img_txt[\"img_text\"]\n",
    "    except FileNotFoundError:\n",
    "        value[\"img_text\"] = None\n",
    "    twits.append(value)\n",
    "df = pd.DataFrame(twits)\n",
    "df.to_feather(data_dir / \"data.feather\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "experienced-front",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>classification</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@FriskDontMiss Nigga https://t.co/cAsaLWEpue#Y...</td>\n",
       "      <td>Homophobe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>My horses are retarded https://t.co/HYhqc6d5WN...</td>\n",
       "      <td>OtherHate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>“NIGGA ON MA MOMMA YOUNGBOY BE SPITTING REAL S...</td>\n",
       "      <td>NotHate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RT xxSuGVNGxx: I ran into this HOLY NIGGA TODA...</td>\n",
       "      <td>NotHate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>“EVERYbody calling you Nigger now!” https://t....</td>\n",
       "      <td>Racist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149818</th>\n",
       "      <td>@svdate @gtconway3d I would just say hes Donny...</td>\n",
       "      <td>NotHate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149819</th>\n",
       "      <td>@Cheftime_Dev congrats my nigga keep on grindi...</td>\n",
       "      <td>NotHate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149820</th>\n",
       "      <td>My nigga big shitty https://t.co/e0snJGBgH9None</td>\n",
       "      <td>NotHate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149821</th>\n",
       "      <td>did she just say “my nigga” to Rich? &amp;amp; she...</td>\n",
       "      <td>NotHate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149822</th>\n",
       "      <td>This nigga Joe Budden said thanos got a galact...</td>\n",
       "      <td>NotHate</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>149823 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     text classification\n",
       "0       @FriskDontMiss Nigga https://t.co/cAsaLWEpue#Y...      Homophobe\n",
       "1       My horses are retarded https://t.co/HYhqc6d5WN...      OtherHate\n",
       "2       “NIGGA ON MA MOMMA YOUNGBOY BE SPITTING REAL S...        NotHate\n",
       "3       RT xxSuGVNGxx: I ran into this HOLY NIGGA TODA...        NotHate\n",
       "4       “EVERYbody calling you Nigger now!” https://t....         Racist\n",
       "...                                                   ...            ...\n",
       "149818  @svdate @gtconway3d I would just say hes Donny...        NotHate\n",
       "149819  @Cheftime_Dev congrats my nigga keep on grindi...        NotHate\n",
       "149820    My nigga big shitty https://t.co/e0snJGBgH9None        NotHate\n",
       "149821  did she just say “my nigga” to Rich? &amp; she...        NotHate\n",
       "149822  This nigga Joe Budden said thanos got a galact...        NotHate\n",
       "\n",
       "[149823 rows x 2 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "twitter2 = pd.read_feather(\"../data/twitter_mutlimodal_hate_speech/data.feather\")\n",
    "labels = twitter2[\"labels_str\"].apply(pd.Series)\n",
    "\n",
    "oh_labels = pd.concat([\n",
    "    pd.get_dummies(labels[li])\n",
    "    for li in labels.columns\n",
    "]).groupby(level=0).max().astype(bool)\n",
    "\n",
    "twitter2[oh_labels.columns] = oh_labels\n",
    "\n",
    "twitter2[\"classification\"] = labels.mode(axis=1)[0]\n",
    "\n",
    "twitter2[\"text\"] = (twitter2[\"tweet_text\"] + twitter2[\"img_text\"].astype(str))\n",
    "# twitter2 = twitter2[[\"tweet_text\", \"text\", \"classification\"]]\n",
    "twitter2 = twitter2[[\"text\", \"classification\"]]\n",
    "twitter2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "satellite-asian",
   "metadata": {},
   "source": [
    "### Appending datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "functioning-nashville",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = conan_dt\n",
    "dataset = dataset.append(conan_dt, ignore_index=True)\n",
    "dataset = dataset.append(lol_data, ignore_index=True)\n",
    "dataset = dataset.append(red_data, ignore_index=True)\n",
    "dataset = dataset.append(twitter_h, ignore_index=True)\n",
    "dataset = dataset.append(abusive, ignore_index=True)\n",
    "dataset = dataset.append(insults, ignore_index=True)\n",
    "dataset = dataset.append(hates, ignore_index=True)\n",
    "dataset = dataset.append(gab_data, ignore_index=True)\n",
    "dataset = dataset.append(twitter2, ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hybrid-refund",
   "metadata": {},
   "source": [
    "### Clean the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dying-respect",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_tweets(vTEXT):\n",
    "    \"\"\"\n",
    "    Removes URLs, tags and more from tweets. Extend it if needed.\n",
    "    \n",
    "    short words: \\b\\w{1,2}\\b\n",
    "    tags starting with @: @\\w*\n",
    "    URL: (https|http)?:\\/\\/(\\w|\\.|\\/|\\?|\\=|\\&|\\%)*\\b\n",
    "    \"\"\"\n",
    "    vTEXT = re.sub(r'\\b\\w{1,2}\\b|@\\w*|(https|http)?:\\/\\/(\\w|\\.|\\/|\\?|\\=|\\&|\\%)*\\b', '', vTEXT, flags=re.MULTILINE)\n",
    "    return(vTEXT)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "antique-rebecca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>classification</th>\n",
       "      <th>text_raw</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>According   recent OFSTED report,  school  Bir...</td>\n",
       "      <td>islamophobic</td>\n",
       "      <td>According to a recent OFSTED report, a school ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Birmingham there   school where girls and boy...</td>\n",
       "      <td>islamophobic</td>\n",
       "      <td>In Birmingham there is a school where girls an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>school  Birningham  still separating girls fr...</td>\n",
       "      <td>islamophobic</td>\n",
       "      <td>A school in Birningham is still separating gir...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The police and politicians are covering  these...</td>\n",
       "      <td>islamophobic</td>\n",
       "      <td>The police and politicians are covering up the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Muslims grooming gangs are protected  the gove...</td>\n",
       "      <td>islamophobic</td>\n",
       "      <td>Muslims grooming gangs are protected by the go...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190117</th>\n",
       "      <td>would just say hes Donny the retard  MOGIF ...</td>\n",
       "      <td>NotHate</td>\n",
       "      <td>@svdate @gtconway3d I would just say hes Donny...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190118</th>\n",
       "      <td>congrats  nigga keep  grinding  AIR Elapsed T...</td>\n",
       "      <td>NotHate</td>\n",
       "      <td>@Cheftime_Dev congrats my nigga keep on grindi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190119</th>\n",
       "      <td>nigga big shitty</td>\n",
       "      <td>NotHate</td>\n",
       "      <td>My nigga big shitty https://t.co/e0snJGBgH9None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190120</th>\n",
       "      <td>did she just say “ nigga”  Rich? &amp;amp; she sai...</td>\n",
       "      <td>NotHate</td>\n",
       "      <td>did she just say “my nigga” to Rich? &amp;amp; she...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190121</th>\n",
       "      <td>This nigga Joe Budden said thanos got  galacti...</td>\n",
       "      <td>NotHate</td>\n",
       "      <td>This nigga Joe Budden said thanos got a galact...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>190122 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     text classification  \\\n",
       "0       According   recent OFSTED report,  school  Bir...   islamophobic   \n",
       "1        Birmingham there   school where girls and boy...   islamophobic   \n",
       "2        school  Birningham  still separating girls fr...   islamophobic   \n",
       "3       The police and politicians are covering  these...   islamophobic   \n",
       "4       Muslims grooming gangs are protected  the gove...   islamophobic   \n",
       "...                                                   ...            ...   \n",
       "190117     would just say hes Donny the retard  MOGIF ...        NotHate   \n",
       "190118   congrats  nigga keep  grinding  AIR Elapsed T...        NotHate   \n",
       "190119                                  nigga big shitty         NotHate   \n",
       "190120  did she just say “ nigga”  Rich? &amp; she sai...        NotHate   \n",
       "190121  This nigga Joe Budden said thanos got  galacti...        NotHate   \n",
       "\n",
       "                                                 text_raw  \n",
       "0       According to a recent OFSTED report, a school ...  \n",
       "1       In Birmingham there is a school where girls an...  \n",
       "2       A school in Birningham is still separating gir...  \n",
       "3       The police and politicians are covering up the...  \n",
       "4       Muslims grooming gangs are protected by the go...  \n",
       "...                                                   ...  \n",
       "190117  @svdate @gtconway3d I would just say hes Donny...  \n",
       "190118  @Cheftime_Dev congrats my nigga keep on grindi...  \n",
       "190119    My nigga big shitty https://t.co/e0snJGBgH9None  \n",
       "190120  did she just say “my nigga” to Rich? &amp; she...  \n",
       "190121  This nigga Joe Budden said thanos got a galact...  \n",
       "\n",
       "[190122 rows x 3 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[\"text_raw\"] = dataset[\"text\"]\n",
    "dataset[\"text\"] = dataset[\"text\"].apply(clean_tweets)\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "progressive-pioneer",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['islamophobic', 'cyberbullying', 'hateful', 'offensive', 'abusive',\n",
       "       'insult', 'Homophobe', 'OtherHate', 'NotHate', 'Racist', 'Sexist',\n",
       "       'Religion'], dtype=object)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.classification.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "stupid-kidney",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.to_csv('../data/main_dataset.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:nlp-course-fri] *",
   "language": "python",
   "name": "conda-env-nlp-course-fri-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
